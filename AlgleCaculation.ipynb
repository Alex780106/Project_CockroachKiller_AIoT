{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17989c3",
   "metadata": {},
   "source": [
    "## 本程式碼為取得戰車在現實生活中與物體的距離，以及在固定轉速與時間的情況下，戰車轉動的x軸pixel數，以便之後調整控制物體追蹤的參數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de667dfa",
   "metadata": {},
   "source": [
    "### 因為之後要透過程式碼控制戰車，我們先建立robot實體物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olive-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import time\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d3895",
   "metadata": {},
   "source": [
    "### 啟動相機並聯動widget讓我們能夠透過jupytor notebook看到實時串流影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaptive-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e5ff6142dd4b7185a09010b74ba9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29910fcf",
   "metadata": {},
   "source": [
    "### 創建拍照存檔資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dental-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created because they already exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "angle_dir = 'dataset/angleCalActualWorld'\n",
    "\n",
    "try:\n",
    "    os.makedirs(angle_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef8ae2",
   "metadata": {},
   "source": [
    "### 創建拍照按鈕以及即時取得當前拍照數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "capture_button = widgets.Button(description='add photo', button_style='success', layout=button_layout)\n",
    "capture_count = widgets.IntText(layout=button_layout, value=len(os.listdir(angle_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb5014",
   "metadata": {},
   "source": [
    "### 定義拍照函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informational-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "\n",
    "def save_photo():\n",
    "    global angle_dir, angle_count\n",
    "    save_snapshot(angle_dir)\n",
    "    capture_count.value = len(os.listdir(angle_dir))\n",
    "    \n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "capture_button.on_click(lambda x: save_photo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcaef86",
   "metadata": {},
   "source": [
    "### 顯示影像串流框及拍照按鈕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1549c6f719a0450eb0431bf4f158f82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428dd571f19b4f8eb9f2c4a8dc5f76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=15, layout=Layout(height='64px', width='128px')), Button(button_style='success', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image)\n",
    "display(widgets.HBox([capture_count, capture_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e1353",
   "metadata": {},
   "source": [
    "### 定義噴灑函數\n",
    "### 透過固定噴頭測量噴灑範圍以及距離，並透過前面定義的拍照函數取得照片以便後續計算參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Jetson.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "output_pin = 21\n",
    "\n",
    "def main():\n",
    "    \n",
    "# 設置為BCM模式\n",
    "\n",
    "    GPIO.setmode(GPIO.BCM) \n",
    "    \n",
    "# 將腳位設定為輸出，並預設為輸出高電位\n",
    "\n",
    "    GPIO.setup(output_pin, GPIO.OUT, initial=GPIO.HIGH)\n",
    "\n",
    "    print(\"Starting demo now! Press CTRL+C to exit\")\n",
    "    curr_value = GPIO.HIGH\n",
    "    try:\n",
    "        while True:\n",
    "            \n",
    "# 每隔4秒鐘切換\n",
    "\n",
    "            time.sleep(4)\n",
    "            print(\"Outputting {} to pin {}\".format(curr_value, output_pin))\n",
    "            GPIO.output(output_pin, curr_value)\n",
    "            curr_value ^= GPIO.HIGH\n",
    "    finally:\n",
    "        GPIO.cleanup()\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d00a39",
   "metadata": {},
   "source": [
    "### 控制戰車轉動，並透過前面定義的拍照函數取得轉動後的照片以便後續計算參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "developmental-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.forward(speed=0.3)\n",
    "time.sleep(3)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "intimate-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_calibration\n",
    "robot.set_motors(0.35, 0.35)\n",
    "time.sleep(3)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prime-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 左轉(左輪向後, 右輪向前)\n",
    "robot.left(speed=0.3)\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "centered-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 右轉(右輪向後, 左輪向前)\n",
    "robot.right(speed=0.3)\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e98b4",
   "metadata": {},
   "source": [
    "### 結束照片蒐集後記得要關閉戰車馬達以及相機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ongoing-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3368724b",
   "metadata": {},
   "source": [
    "### 載入YOLOv5s模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legendary-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "YOLOv5 🚀 2022-9-27 Python-3.6.9 torch-1.8.0 CUDA:0 (NVIDIA Tegra X1, 3964MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Python 3.7.0 is required by YOLOv5, but Python 3.6.9 is currently installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# 載入自行訓練的 YOLOv5 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='./models/yolov5s62best.pt', force_reload=True)\n",
    "\n",
    "# 設定 IoU 門檻值\n",
    "model.iou = 0.3\n",
    "\n",
    "# 設定信心門檻值\n",
    "model.conf = 0.5\n",
    "\n",
    "\n",
    "def preprocess_yolo(camera_value):\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9efd08",
   "metadata": {},
   "source": [
    "### 將前述拍攝的照片透過YOLOv5模型取得偵測物件Bounding Box 左上角、右下角 x, y座標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beginning-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 149x339 (no detections)\n",
      "Speed: 13.7ms pre-process, 82.0ms inference, 2.3ms NMS per image at shape (1, 3, 128, 224)\n",
      "Saved 1 image to \u001b[1mruns/detect/exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_name = 'Spray_S'\n",
    "\n",
    "img_1 = '/workspace/jetbot/notebooks/object_following/cockroach_imgs_internet/images_33.jpg'\n",
    "\n",
    "results = model(img_1, size=224)\n",
    "\n",
    "results.print()\n",
    "\n",
    "results.save()\n",
    "\n",
    "image_number = 0\n",
    "object_number = 0\n",
    "\n",
    "HighestConfidenceResult = results.pandas().xyxy[image_number].loc[object_number]\n",
    "print(HighestConfidenceResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "unique-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: 35.07\n",
      "w: 33.19\n",
      "central_x: 100\n",
      "central_y: 119\n",
      "distance: 13.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frame_width = 224\n",
    "frame_height = 224\n",
    "\n",
    "frame_central_x = int(frame_width/2)\n",
    "frame_central_y = int(frame_height/2)\n",
    "\n",
    "xmin = HighestConfidenceResult['xmin']\n",
    "xmax = HighestConfidenceResult['xmax']\n",
    "ymin = HighestConfidenceResult['ymin']\n",
    "ymax = HighestConfidenceResult['ymax']\n",
    "\n",
    "# 找出BBox中心點的x\n",
    "w = xmax - xmin\n",
    "central_x = int(xmin + (w/2))\n",
    "\n",
    "\n",
    "# 找出BBox中心點的y\n",
    "h = ymax - ymin\n",
    "central_y = int(ymin + (h/2))\n",
    "\n",
    "\n",
    "img = cv2.imread('/workspace/jetbot/notebooks/object_following/dataset/angleCalActualWorld/{}.jpg'.format(img_name))\n",
    "\n",
    "cv2.line(img, (frame_central_x, 0), (frame_central_x, frame_height), (255, 0, 0), 2)  # Vertical line through frame central point\n",
    "cv2.line(img, (0, frame_central_y), (frame_width, frame_central_y), (255, 0, 0), 2)  # Horizontal line through frame central point\n",
    "cv2.circle(img, (central_x, central_y), 10, (255, 255, 0), 3)  # BBox central point\n",
    "cv2.line(img, (frame_central_x, frame_central_y), (central_x, central_y), (0, 255, 0), 3)  # Line from central point to BBox central point\n",
    "cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255), 2)  # \n",
    "\n",
    "distance = np.sqrt((frame_central_x - central_x)**2 + (frame_central_y - central_y)**2)\n",
    "\n",
    "print('h: {:.2f}'.format(h))\n",
    "print('w: {:.2f}'.format(w))\n",
    "print('central_x:', central_x)\n",
    "print('central_y:', central_y)\n",
    "print('distance: {:.2f}'.format(distance))\n",
    "\n",
    "\n",
    "cv2.imwrite('{}_draw.jpg'.format(img_name), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
