{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "olive-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "import time\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaptive-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e5ff6142dd4b7185a09010b74ba9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dental-impression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories not created because they already exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "angle_dir = 'dataset/angleCalActualWorld'\n",
    "\n",
    "try:\n",
    "    os.makedirs(angle_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unavailable-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "capture_button = widgets.Button(description='add photo', button_style='success', layout=button_layout)\n",
    "capture_count = widgets.IntText(layout=button_layout, value=len(os.listdir(angle_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "informational-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "\n",
    "def save_photo():\n",
    "    global angle_dir, angle_count\n",
    "    save_snapshot(angle_dir)\n",
    "    capture_count.value = len(os.listdir(angle_dir))\n",
    "    \n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "capture_button.on_click(lambda x: save_photo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1549c6f719a0450eb0431bf4f158f82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "428dd571f19b4f8eb9f2c4a8dc5f76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=15, layout=Layout(height='64px', width='128px')), Button(button_style='success', ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(image)\n",
    "display(widgets.HBox([capture_count, capture_button]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting demo now! Press CTRL+C to exit\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n",
      "Outputting 1 to pin 21\n",
      "Outputting 0 to pin 21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d10c313d059f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d10c313d059f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# ÊØèÈöî1ÁßíÈêòÂàáÊèõ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Outputting {} to pin {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_pin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mGPIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_pin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import Jetson.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "output_pin = 21\n",
    "\n",
    "def main():\n",
    "    \n",
    "# Ë®≠ÁΩÆÁÇ∫BCMÊ®°Âºè\n",
    "\n",
    "    GPIO.setmode(GPIO.BCM) \n",
    "    \n",
    "# Â∞áËÖ≥‰ΩçË®≠ÂÆöÁÇ∫Ëº∏Âá∫Ôºå‰∏¶È†êË®≠ÁÇ∫Ëº∏Âá∫È´òÈõª‰Ωç\n",
    "\n",
    "    GPIO.setup(output_pin, GPIO.OUT, initial=GPIO.HIGH)\n",
    "\n",
    "    print(\"Starting demo now! Press CTRL+C to exit\")\n",
    "    curr_value = GPIO.HIGH\n",
    "    try:\n",
    "        while True:\n",
    "            \n",
    "# ÊØèÈöî1ÁßíÈêòÂàáÊèõ\n",
    "\n",
    "            time.sleep(4)\n",
    "            print(\"Outputting {} to pin {}\".format(curr_value, output_pin))\n",
    "            GPIO.output(output_pin, curr_value)\n",
    "            curr_value ^= GPIO.HIGH\n",
    "    finally:\n",
    "        GPIO.cleanup()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "developmental-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.forward(speed=0.3)\n",
    "time.sleep(3)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "intimate-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward_calibration\n",
    "robot.set_motors(0.35, 0.35)\n",
    "time.sleep(3)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "prime-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∑¶ËΩâ(Â∑¶Ëº™ÂêëÂæå, Âè≥Ëº™ÂêëÂâç)\n",
    "robot.left(speed=0.3)\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "centered-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Âè≥ËΩâ(Âè≥Ëº™ÂêëÂæå, Â∑¶Ëº™ÂêëÂâç)\n",
    "robot.right(speed=0.3)\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ongoing-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "legendary-shirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
      "YOLOv5 üöÄ 2022-9-27 Python-3.6.9 torch-1.8.0 CUDA:0 (NVIDIA Tegra X1, 3964MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è Python 3.7.0 is required by YOLOv5, but Python 3.6.9 is currently installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# ËºâÂÖ•Ëá™Ë°åË®ìÁ∑¥ÁöÑ YOLOv5 Ê®°Âûã\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='./models/yolov5s62best.pt', force_reload=True)\n",
    "\n",
    "# Ë®≠ÂÆö IoU ÈñÄÊ™ªÂÄº\n",
    "model.iou = 0.3\n",
    "\n",
    "# Ë®≠ÂÆö‰ø°ÂøÉÈñÄÊ™ªÂÄº\n",
    "model.conf = 0.5\n",
    "\n",
    "\n",
    "def preprocess_yolo(camera_value):\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (224, 224))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "beginning-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 149x339 (no detections)\n",
      "Speed: 13.7ms pre-process, 82.0ms inference, 2.3ms NMS per image at shape (1, 3, 128, 224)\n",
      "Saved 1 image to \u001b[1mruns/detect/exp5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "img_name = 'Spray_S'\n",
    "\n",
    "img_1 = '/workspace/jetbot/notebooks/object_following/cockroach_imgs_internet/images_33.jpg'\n",
    "\n",
    "img_2 = '/workspace/jetbot/notebooks/object_following/dataset/angleCalActualWorld/Robot0.3Right1secToCentral.jpg'\n",
    "\n",
    "img_3 = '/workspace/jetbot/notebooks/object_following/dataset/angleCalActualWorld/OriginalWithCockroach.jpg'\n",
    "\n",
    "results = model(img_1, size=224)\n",
    "\n",
    "results.print()\n",
    "\n",
    "results.save()\n",
    "\n",
    "# image_number = 0\n",
    "# object_number = 0\n",
    "\n",
    "# HighestConfidenceResult = results.pandas().xyxy[image_number].loc[object_number]\n",
    "# print(HighestConfidenceResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "unique-muscle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: 35.07\n",
      "w: 33.19\n",
      "central_x: 100\n",
      "central_y: 119\n",
      "distance: 13.89\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frame_width = 224\n",
    "frame_height = 224\n",
    "\n",
    "frame_central_x = int(frame_width/2)\n",
    "frame_central_y = int(frame_height/2)\n",
    "\n",
    "xmin = HighestConfidenceResult['xmin']\n",
    "xmax = HighestConfidenceResult['xmax']\n",
    "ymin = HighestConfidenceResult['ymin']\n",
    "ymax = HighestConfidenceResult['ymax']\n",
    "\n",
    "# ÊâæÂá∫BBox‰∏≠ÂøÉÈªûÁöÑx\n",
    "w = xmax - xmin\n",
    "central_x = int(xmin + (w/2))\n",
    "\n",
    "\n",
    "# ÊâæÂá∫BBox‰∏≠ÂøÉÈªûÁöÑy\n",
    "h = ymax - ymin\n",
    "central_y = int(ymin + (h/2))\n",
    "\n",
    "\n",
    "img = cv2.imread('/workspace/jetbot/notebooks/object_following/dataset/angleCalActualWorld/{}.jpg'.format(img_name))\n",
    "\n",
    "cv2.line(img, (frame_central_x, 0), (frame_central_x, frame_height), (255, 0, 0), 2)  # Vertical line through frame central point\n",
    "cv2.line(img, (0, frame_central_y), (frame_width, frame_central_y), (255, 0, 0), 2)  # Horizontal line through frame central point\n",
    "cv2.circle(img, (central_x, central_y), 10, (255, 255, 0), 3)  # BBox central point\n",
    "cv2.line(img, (frame_central_x, frame_central_y), (central_x, central_y), (0, 255, 0), 3)  # Line from central point to BBox central point\n",
    "cv2.rectangle(img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 0, 255), 2)  # \n",
    "\n",
    "distance = np.sqrt((frame_central_x - central_x)**2 + (frame_central_y - central_y)**2)\n",
    "\n",
    "print('h: {:.2f}'.format(h))\n",
    "print('w: {:.2f}'.format(w))\n",
    "print('central_x:', central_x)\n",
    "print('central_y:', central_y)\n",
    "print('distance: {:.2f}'.format(distance))\n",
    "\n",
    "\n",
    "cv2.imwrite('{}_draw.jpg'.format(img_name), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
